# Epsilon: Нейронная сеть для верификации подписей

Сиамская нейронная сеть для верификации подписей, основанная на комбинации CNN, LSTM и Attention механизмов.

## Настройка и запуск

*В этих примерах все команды запускаются в powershell из корневого каталога проекта*

- Установить Node.js и Python зависимости
- Запустить powershell скрипт `> start.ps1`

- Если нет датасета, то запустить `> cd datasets && python dataset_preparation.py`
  - Установить `ENABLE_OUTPUT_BASE = True`, чтобы сохранить подписи в `data/dev`
- Чтобы скопировать подписи, учавствовавшие в обучении, в `data/eval`, запустить `> python copy_test_users.py` (`--help` для справки, `--users-file "...\test_users.txt"` - путь к файлу с ID пользователей не учавствовавших в обучении)
- Чтобы вычислить эмбеддинги для всех пользователей тестовой выборки обучения, запустить `> cd nn && python enroll_eval.py`

## Структура проекта

- `base` - источники
- `nn` - нейронные сети
  - Нумерация версий нейронных сетей: alpha, beta, gamma, delta и т.д.
  - `inference.py` - работа с обученной моделью
  - `enroll_eval.py` - вычисление эмбеддингов для всех пользователей тестовой выборки обучения и сохранения их в директорию эмбеддингов
  - `verify_eval.py` - вычисление статистики по верификации подписей для всех пользователей тестовой выборки обучения
  - `{версия}/v{число}/` - подверсия нейронной, включающая файл модели, конфигурацию, список тестовых пользователей (опционально статистику обучения)
- `server` - сервер для веб интерфейса
- `colab` - сервер для сохранения данных из Google Colab (WIP)
- `datasets` - подготовка датасетов
  - `preprocessing.py` - модуль для предварительной обработки данных
  - `dataset_preparation.py` - обход, обработка и запись данных в lmdb
  - `print_dataset.py` - вывод статистики по датасету (устаревший, из-за налачия нового скрипта `debug_data_quality.py` начиная с eta)
- `data` - обработанные данные (подписи, эмбеддинги)
- `compile_md.py` - скрипт для компиляции основных скриптов (чтобы, например, перекинуть в llm)
- `copy_test_users.py` - скрипт для копирования тестовых пользователей из `data/dev` в `data/eval`, основываясь на списке пользователей в `nn/{версия}/v{число}/test_users.txt`

## Различия между основными версиями

Основные версии: `delta`, `delta_reworked`, `eta`

- `delta` - оффлайн триплет майнинг, код монолитный, без чекпоинтов и других фич, лучший EER ~11% (скорее всего этот результат был везением)
- `eta` - онлайн триплет майнинг, код модульный, лучший EER ~17% (он был утерян, rest in pepperoni)
- `delta_reworked` - оффлайн триплет майнинг, получен из `delta`, путем прогона через ИИ с использованием `eta` как пример структурирования

В теории, `eta` должна быть лучше `delta`

## Пометки

- `inference.py` стоит переделать в серверную версию, ибо инициализация модели занимает слишком много времени при каждом запросе
- Папку `/data/` и подпапки `dev/`, `eval/`, `emb/`, `tmp/` - лучше создать вручную, может быть в каком-то месте не предусмотрено автоматическое создание этих папок
- `print_dataset.py` и `debug_triplets.py` - объединены в `debug_data_quality.py` начиная с версии `eta`
- оффлайн майнинг
  - `+`: стабильное снижение EER, простой подбор гиперпараметров
  - `-`: в теории, хуже лучший EER
- онлайн майнинг
  - `+`: в теории, лучше результат; быстрее эпохи; сразу хороший результат (EER ~20%), НО при хороших параметрах
   - `-`: очень специфический подбор гиперпараметров, нужно уделять особое внимание функции майнинга
- `colab/`, как механизм сохранения данных, можно упростить до простого логгирования в терминал IDE, уже имующееся сохранение в Google Drive - вполне достаточно
- `optuna_study.py` - блин, прикольно, но, видимо, нужно больше эпох уделять одному эксперименту, ибо гиперпараметры полученные парой эпох слишком далеки от наиболее качественных в середине обучения
- umap - как механизм визуализации - хорошо, но странно себя ведет при визуализации нескольких эмбеддингов пользователей и при одном среднем эмбеддинге на пользователя. Из наблюдения: явно было видно что кластеры пользователей друг на друга накладываются, но среднием эмбеддинги находятся на приемлиемом расстоянии друг от друга, что не логично. Может стоит рассмотреть T-SNE
- можно придумать механизм автоопределения места работы (локально/Colab), чтобы агент Cursor мог автоматически проводить отладку локально, а не пытался подключить локальный файл, с путем к Google Drive
- В eta, как минимум, есть несколько мест где можно применить k-means (если верить ИИ)
- В веб интерфейсе, используется интерполяция, чтобы увеличить количество временных шагов в подписи в 2 раза (dt: ~16мс -> ~8мс). ВОЗМОЖНО, то что во всех данных используемых для обучения dt фиксированно 10мс - это может сказываться на результате инференса (хотя для времени и используется аугментация, она вроде не слишком большая). С этим можно поэкспериментировать: "занулить" некоторые временные шаги, сделать +/- "всплески" и т.п.
- Для онлайн майнинга, возможно, наиболее оптимальные гиперпараметры сразу дают хороший результат, т.е. чем лучше сет гиперпараметров, тем меньше EER на первой эпохе
- В ПДФнике, помимо понятных мне первых и вторых проихводных по t, x, y, p, используется еще некоторые "специфические". Сейчас этих "специфических" 3, можно добавить оставшиеся
- в архитекутре модели, скорее всего CNN и LSTM уже достаточно оптимальны, лучше уделить внимание Attention механизму и нормализации эмбеддинга (особенно нормализации, его отсутсвие/наличие может иметь влияние в зависимости от использованного типа майнинга)
- впредь не использовать аугментацию в подготовке датасета, pytorch умеет делать это на лету, а numpy, возможно, оказалась каличной
- аугментация в подготовке датасета все еще есть, но отключена. Сейчас количество аугментов регулируется в `config.py`
- то-ли до `beta`, то-ли до `gamma` все еще использовалась функция потерь `ContrastiveLoss`, в теории, она должна быть хуже `TripletLoss`, но можно еще раз вернуться к ней, просто эксперимента ради (валятся где-то в старых коммитах на гитхабе)
- в последнем обучении `delta_reworked` резко упал TrainLoss с 0.1x до 0.00x за несколько эпох, но EER продолжил неплохо снижаться - стоит обсудить с ИИ

**В курсовой использовалась статистика из `delta`, но описание пайплайна и код из `delta_reworked`. В теории, должно быть одинаково, не учитывая рандом в процессе обучения.**