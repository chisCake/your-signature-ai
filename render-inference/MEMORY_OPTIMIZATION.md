# Оптимизация памяти для Render Inference Server

## Проблема
Сервер выходил из памяти (OOM) при загрузке модели на Render с лимитом 512MB.

## Реализованные оптимизации

### 1. Ленивая загрузка модели
- Модель загружается только при первом использовании, а не при старте сервера
- Значительно снижает потребление памяти при запуске

### 2. Оптимизированная загрузка PyTorch
- Использование `weights_only=True` при загрузке checkpoint
- Оптимизированные настройки PyTorch для экономии памяти
- Автоматическая очистка кэша после загрузки

### 3. Мониторинг памяти
- Добавлены эндпоинты для мониторинга использования памяти
- Логирование использования памяти на разных этапах
- Предупреждения при превышении лимитов

### 4. Управление жизненным циклом модели
- Возможность выгрузки модели из памяти
- Принудительная загрузка при необходимости
- Автоматическая очистка ресурсов

## Новые эндпоинты

### GET /memory
Получение информации об использовании памяти:
```json
{
  "memory": {
    "rss_mb": 245.6,
    "vms_mb": 1024.0,
    "model_loaded": true,
    "gpu_allocated_mb": 0.0,
    "gpu_cached_mb": 0.0
  },
  "model": {
    "status": "loaded",
    "total_parameters": 1234567
  }
}
```

### POST /model/unload
Выгрузка модели из памяти для экономии ресурсов.

### POST /model/load
Принудительная загрузка модели в память.

## Переменные окружения

### LAZY_LOADING
- `true` (по умолчанию) - использовать ленивую загрузку
- `false` - загружать модель при старте

### ENVIRONMENT
- `production` - автоматически включает ленивую загрузку
- `development` - может отключить ленивую загрузку для удобства разработки

## Конфигурация памяти

Файл `memory_config.py` содержит настройки для оптимизации памяти:

- Лимиты памяти и пороги предупреждений
- Настройки PyTorch для экономии памяти
- Параметры загрузки модели

## Результат

После оптимизации:
- Сервер запускается без загрузки модели в память
- Модель загружается только при первом запросе к API
- Добавлен мониторинг и управление памятью
- Значительно снижено потребление памяти при старте

## Тестирование

Для тестирования оптимизаций:

1. Проверьте статус памяти: `GET /memory`
2. Убедитесь, что модель не загружена при старте
3. Сделайте запрос к API - модель должна загрузиться автоматически
4. Проверьте использование памяти после загрузки модели
5. При необходимости выгрузите модель: `POST /model/unload`
